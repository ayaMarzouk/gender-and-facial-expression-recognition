{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_train.npy', 'X_train.npy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from random import shuffle\n",
    "from joblib import load, dump\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.applications import VGG16\n",
    "from tqdm import tqdm\n",
    "from math import *\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "IMG_SIZE = 350\n",
    "\n",
    "X_train, y_train = [], []\n",
    "print (os.listdir('../input/facialcnn'))\n",
    "if os.path.exists('../input/facialcnn/X_train.npy') and os.path.exists('../input/facialcnn/y_train.npy'):\n",
    "    X_train = np.load('../input/facialcnn/X_train.npy')\n",
    "    y_train = np.load('../input/facialcnn/y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8274, 350, 350, 3)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7032 samples, validate on 1242 samples\n",
      "Epoch 1/20\n",
      "7032/7032 [==============================] - 150s 21ms/step - loss: 1.6015 - acc: 0.4525 - val_loss: 1.4017 - val_acc: 0.4750\n",
      "Epoch 2/20\n",
      "7032/7032 [==============================] - 140s 20ms/step - loss: 0.7891 - acc: 0.7467 - val_loss: 3.5853 - val_acc: 0.2061\n",
      "Epoch 3/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.4067 - acc: 0.8685 - val_loss: 2.5901 - val_acc: 0.2915\n",
      "Epoch 4/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.2666 - acc: 0.9093 - val_loss: 0.3389 - val_acc: 0.8873\n",
      "Epoch 5/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.2254 - acc: 0.9236 - val_loss: 0.2701 - val_acc: 0.9106\n",
      "Epoch 6/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1893 - acc: 0.9376 - val_loss: 0.5788 - val_acc: 0.8124\n",
      "Epoch 7/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1673 - acc: 0.9394 - val_loss: 0.2325 - val_acc: 0.9211\n",
      "Epoch 8/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1594 - acc: 0.9465 - val_loss: 0.2327 - val_acc: 0.9187\n",
      "Epoch 9/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1427 - acc: 0.9512 - val_loss: 0.1784 - val_acc: 0.9356\n",
      "Epoch 10/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1262 - acc: 0.9556 - val_loss: 0.2607 - val_acc: 0.9219\n",
      "Epoch 11/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1214 - acc: 0.9583 - val_loss: 0.2753 - val_acc: 0.9155\n",
      "Epoch 12/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1660 - acc: 0.9470 - val_loss: 0.3389 - val_acc: 0.8865\n",
      "Epoch 13/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1551 - acc: 0.9458 - val_loss: 0.2098 - val_acc: 0.9332\n",
      "Epoch 14/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1182 - acc: 0.9583 - val_loss: 0.1685 - val_acc: 0.9340\n",
      "Epoch 15/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.1094 - acc: 0.9627 - val_loss: 0.1512 - val_acc: 0.9517\n",
      "Epoch 16/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.0992 - acc: 0.9650 - val_loss: 0.2004 - val_acc: 0.9348\n",
      "Epoch 17/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.0940 - acc: 0.9652 - val_loss: 0.1755 - val_acc: 0.9420\n",
      "Epoch 18/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.0903 - acc: 0.9687 - val_loss: 0.1936 - val_acc: 0.9428\n",
      "Epoch 19/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.0752 - acc: 0.9753 - val_loss: 0.1955 - val_acc: 0.9420\n",
      "Epoch 20/20\n",
      "7032/7032 [==============================] - 141s 20ms/step - loss: 0.0700 - acc: 0.9751 - val_loss: 0.1641 - val_acc: 0.9493\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "\n",
    "PretrainedVGG = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "model = Sequential()\n",
    "model.add(PretrainedVGG)\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile( loss = \"categorical_crossentropy\", \n",
    "              optimizer = sgd, \n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, validation_split=0.15)\n",
    "model.save_weights('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
